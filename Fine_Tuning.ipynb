{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpowhIKiPRTh"
   },
   "source": [
    "### üìå Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMyYTJ02hnGy",
    "outputId": "e5efd436-e4da-4dd6-cedc-ae1ee598f314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqlQU-cOfTzH"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCvkhMBffTzR"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yixXkdOhfTzi",
    "outputId": "7aaae56a-7e46-499c-cf53-7945e52878af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 Conv1\n",
      "2 bn_Conv1\n",
      "3 Conv1_relu\n",
      "4 expanded_conv_depthwise\n",
      "5 expanded_conv_depthwise_BN\n",
      "6 expanded_conv_depthwise_relu\n",
      "7 expanded_conv_project\n",
      "8 expanded_conv_project_BN\n",
      "9 block_1_expand\n",
      "10 block_1_expand_BN\n",
      "11 block_1_expand_relu\n",
      "12 block_1_pad\n",
      "13 block_1_depthwise\n",
      "14 block_1_depthwise_BN\n",
      "15 block_1_depthwise_relu\n",
      "16 block_1_project\n",
      "17 block_1_project_BN\n",
      "18 block_2_expand\n",
      "19 block_2_expand_BN\n",
      "20 block_2_expand_relu\n",
      "21 block_2_depthwise\n",
      "22 block_2_depthwise_BN\n",
      "23 block_2_depthwise_relu\n",
      "24 block_2_project\n",
      "25 block_2_project_BN\n",
      "26 block_2_add\n",
      "27 block_3_expand\n",
      "28 block_3_expand_BN\n",
      "29 block_3_expand_relu\n",
      "30 block_3_pad\n",
      "31 block_3_depthwise\n",
      "32 block_3_depthwise_BN\n",
      "33 block_3_depthwise_relu\n",
      "34 block_3_project\n",
      "35 block_3_project_BN\n",
      "36 block_4_expand\n",
      "37 block_4_expand_BN\n",
      "38 block_4_expand_relu\n",
      "39 block_4_depthwise\n",
      "40 block_4_depthwise_BN\n",
      "41 block_4_depthwise_relu\n",
      "42 block_4_project\n",
      "43 block_4_project_BN\n",
      "44 block_4_add\n",
      "45 block_5_expand\n",
      "46 block_5_expand_BN\n",
      "47 block_5_expand_relu\n",
      "48 block_5_depthwise\n",
      "49 block_5_depthwise_BN\n",
      "50 block_5_depthwise_relu\n",
      "51 block_5_project\n",
      "52 block_5_project_BN\n",
      "53 block_5_add\n",
      "54 block_6_expand\n",
      "55 block_6_expand_BN\n",
      "56 block_6_expand_relu\n",
      "57 block_6_pad\n",
      "58 block_6_depthwise\n",
      "59 block_6_depthwise_BN\n",
      "60 block_6_depthwise_relu\n",
      "61 block_6_project\n",
      "62 block_6_project_BN\n",
      "63 block_7_expand\n",
      "64 block_7_expand_BN\n",
      "65 block_7_expand_relu\n",
      "66 block_7_depthwise\n",
      "67 block_7_depthwise_BN\n",
      "68 block_7_depthwise_relu\n",
      "69 block_7_project\n",
      "70 block_7_project_BN\n",
      "71 block_7_add\n",
      "72 block_8_expand\n",
      "73 block_8_expand_BN\n",
      "74 block_8_expand_relu\n",
      "75 block_8_depthwise\n",
      "76 block_8_depthwise_BN\n",
      "77 block_8_depthwise_relu\n",
      "78 block_8_project\n",
      "79 block_8_project_BN\n",
      "80 block_8_add\n",
      "81 block_9_expand\n",
      "82 block_9_expand_BN\n",
      "83 block_9_expand_relu\n",
      "84 block_9_depthwise\n",
      "85 block_9_depthwise_BN\n",
      "86 block_9_depthwise_relu\n",
      "87 block_9_project\n",
      "88 block_9_project_BN\n",
      "89 block_9_add\n",
      "90 block_10_expand\n",
      "91 block_10_expand_BN\n",
      "92 block_10_expand_relu\n",
      "93 block_10_depthwise\n",
      "94 block_10_depthwise_BN\n",
      "95 block_10_depthwise_relu\n",
      "96 block_10_project\n",
      "97 block_10_project_BN\n",
      "98 block_11_expand\n",
      "99 block_11_expand_BN\n",
      "100 block_11_expand_relu\n",
      "101 block_11_depthwise\n",
      "102 block_11_depthwise_BN\n",
      "103 block_11_depthwise_relu\n",
      "104 block_11_project\n",
      "105 block_11_project_BN\n",
      "106 block_11_add\n",
      "107 block_12_expand\n",
      "108 block_12_expand_BN\n",
      "109 block_12_expand_relu\n",
      "110 block_12_depthwise\n",
      "111 block_12_depthwise_BN\n",
      "112 block_12_depthwise_relu\n",
      "113 block_12_project\n",
      "114 block_12_project_BN\n",
      "115 block_12_add\n",
      "116 block_13_expand\n",
      "117 block_13_expand_BN\n",
      "118 block_13_expand_relu\n",
      "119 block_13_pad\n",
      "120 block_13_depthwise\n",
      "121 block_13_depthwise_BN\n",
      "122 block_13_depthwise_relu\n",
      "123 block_13_project\n",
      "124 block_13_project_BN\n",
      "125 block_14_expand\n",
      "126 block_14_expand_BN\n",
      "127 block_14_expand_relu\n",
      "128 block_14_depthwise\n",
      "129 block_14_depthwise_BN\n",
      "130 block_14_depthwise_relu\n",
      "131 block_14_project\n",
      "132 block_14_project_BN\n",
      "133 block_14_add\n",
      "134 block_15_expand\n",
      "135 block_15_expand_BN\n",
      "136 block_15_expand_relu\n",
      "137 block_15_depthwise\n",
      "138 block_15_depthwise_BN\n",
      "139 block_15_depthwise_relu\n",
      "140 block_15_project\n",
      "141 block_15_project_BN\n",
      "142 block_15_add\n",
      "143 block_16_expand\n",
      "144 block_16_expand_BN\n",
      "145 block_16_expand_relu\n",
      "146 block_16_depthwise\n",
      "147 block_16_depthwise_BN\n",
      "148 block_16_depthwise_relu\n",
      "149 block_16_project\n",
      "150 block_16_project_BN\n",
      "151 Conv_1\n",
      "152 Conv_1_bn\n",
      "153 out_relu\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/·Ñè·Ö≥·ÜØ·ÑÖ·Ö°·Ñã·ÖÆ·ÑÉ·Ö≥ ·Ñë·Ö≥·ÜØ·ÑÖ·Ö¢·Ü∫·Ñë·Ö©·Ü∑/·Ñê·Öµ·Ü∑ ·Ñë·Ö≥·ÑÖ·Ö©·Ñå·Ö¶·Ü®·Ñê·Ö≥ (·Ñè·Ö≥·ÜØ·Ñë·Ö≥·ÜØ)/Final Data')\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "mobilenet_model = mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', \n",
    "                                              input_shape=input_shape)\n",
    "\n",
    "for i, layer in enumerate(mobilenet_model.layers):\n",
    "   print(i, layer.name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Rt0hwedlR0W",
    "outputId": "d70ff617-fb05-4c1d-cf7b-cc44733aad1f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,198,080\n",
      "Non-trainable params: 59,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet_model.trainable = True\n",
    "\n",
    "for layer in mobilenet_model.layers[:36]:\n",
    "  layer.trainable = False\n",
    "\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSAf0RswmqET",
    "outputId": "db5a2fdd-b75a-4103-f161-bbf734363582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mobilenet_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaZsZ7mkpJdJ",
    "outputId": "c44bb054-1adb-493f-c560-116a8ce33c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 images belonging to 2 classes.\n",
      "Found 152 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=30, \n",
    "                                  # shear_range=5.5,  \n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  fill_mode='reflect')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('./model_data/ÌòºÌï©_ÏûêÏÑ∏/train',\n",
    "                                                    target_size=(224, 224),       #ÏΩîÎìú Î≥ÄÍ≤Ω\n",
    "                                                    batch_size=5,\n",
    "                                                    classes = ['good', 'bad'],    # ÏΩîÎìú Ï∂îÍ∞Ä\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('./model_data/ÌòºÌï©_ÏûêÏÑ∏/test',\n",
    "                                                    target_size=(224, 224),       #ÏΩîÎìú Î≥ÄÍ≤Ω\n",
    "                                                    batch_size=5,\n",
    "                                                    classes = ['good', 'bad'],    # ÏΩîÎìú Ï∂îÍ∞Ä\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lf5SXdbrdNb0",
    "outputId": "4deda15d-0f47-47a3-d410-f6c263d43583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 0, 'bad': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LstaLI4mUYJ"
   },
   "source": [
    "## ‚úîÔ∏è ÏùºÎ∞ò Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-tHqRZPMpBh"
   },
   "source": [
    "### üëâ epoch : 100 Í∏∞Ï§ÄÏúºÎ°ú ÎèåÎ¶¨Í∏∞ (model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIEXNMLGMpBn",
    "outputId": "7338dabb-e00d-4170-c580-5b9f2fd6eacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 62721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,320,705\n",
      "Trainable params: 2,260,801\n",
      "Non-trainable params: 59,904\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(mobilenet_model)\n",
    "model1.add(Flatten())       \n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN6g6LLvMpBo",
    "outputId": "a2d4f2fe-2caf-4f72-ad05-a6bceb0ab2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.5335\n",
      "Epoch 1: val_loss improved from inf to 0.77938, saving model to ./model/01-0.7794.hdf5\n",
      "90/90 [==============================] - 13s 102ms/step - loss: 0.9569 - accuracy: 0.5335 - val_loss: 0.7794 - val_accuracy: 0.5526\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.5156\n",
      "Epoch 2: val_loss improved from 0.77938 to 0.72181, saving model to ./model/02-0.7218.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.9077 - accuracy: 0.5156 - val_loss: 0.7218 - val_accuracy: 0.6118\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.6205\n",
      "Epoch 3: val_loss did not improve from 0.72181\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.7625 - accuracy: 0.6205 - val_loss: 0.7429 - val_accuracy: 0.6118\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.5871\n",
      "Epoch 4: val_loss improved from 0.72181 to 0.63964, saving model to ./model/04-0.6396.hdf5\n",
      "90/90 [==============================] - 9s 95ms/step - loss: 0.7359 - accuracy: 0.5871 - val_loss: 0.6396 - val_accuracy: 0.6382\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.6562\n",
      "Epoch 5: val_loss improved from 0.63964 to 0.62242, saving model to ./model/05-0.6224.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.6651 - accuracy: 0.6562 - val_loss: 0.6224 - val_accuracy: 0.6513\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.6808\n",
      "Epoch 6: val_loss improved from 0.62242 to 0.55004, saving model to ./model/06-0.5500.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.6346 - accuracy: 0.6808 - val_loss: 0.5500 - val_accuracy: 0.6974\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6897\n",
      "Epoch 7: val_loss did not improve from 0.55004\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.6159 - accuracy: 0.6897 - val_loss: 0.5523 - val_accuracy: 0.7105\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7455\n",
      "Epoch 8: val_loss improved from 0.55004 to 0.52042, saving model to ./model/08-0.5204.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.5397 - accuracy: 0.7455 - val_loss: 0.5204 - val_accuracy: 0.7303\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7522\n",
      "Epoch 9: val_loss improved from 0.52042 to 0.45309, saving model to ./model/09-0.4531.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.5309 - accuracy: 0.7522 - val_loss: 0.4531 - val_accuracy: 0.7632\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.7277\n",
      "Epoch 10: val_loss did not improve from 0.45309\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.5163 - accuracy: 0.7277 - val_loss: 0.5758 - val_accuracy: 0.7303\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7388\n",
      "Epoch 11: val_loss did not improve from 0.45309\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.5143 - accuracy: 0.7388 - val_loss: 0.4917 - val_accuracy: 0.7961\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7723\n",
      "Epoch 12: val_loss improved from 0.45309 to 0.44408, saving model to ./model/12-0.4441.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.4744 - accuracy: 0.7723 - val_loss: 0.4441 - val_accuracy: 0.7895\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7857\n",
      "Epoch 13: val_loss did not improve from 0.44408\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.4749 - accuracy: 0.7857 - val_loss: 0.5072 - val_accuracy: 0.7829\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.8058\n",
      "Epoch 14: val_loss did not improve from 0.44408\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.4301 - accuracy: 0.8058 - val_loss: 0.4524 - val_accuracy: 0.8026\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7902\n",
      "Epoch 15: val_loss did not improve from 0.44408\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.4376 - accuracy: 0.7902 - val_loss: 0.4471 - val_accuracy: 0.7961\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.7902\n",
      "Epoch 16: val_loss did not improve from 0.44408\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.4648 - accuracy: 0.7902 - val_loss: 0.5398 - val_accuracy: 0.7763\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.8170\n",
      "Epoch 17: val_loss improved from 0.44408 to 0.41151, saving model to ./model/17-0.4115.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.4362 - accuracy: 0.8170 - val_loss: 0.4115 - val_accuracy: 0.8487\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8125\n",
      "Epoch 18: val_loss improved from 0.41151 to 0.38458, saving model to ./model/18-0.3846.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.3846 - val_accuracy: 0.8487\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8371\n",
      "Epoch 19: val_loss improved from 0.38458 to 0.32818, saving model to ./model/19-0.3282.hdf5\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.3677 - accuracy: 0.8371 - val_loss: 0.3282 - val_accuracy: 0.8750\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.8594\n",
      "Epoch 20: val_loss improved from 0.32818 to 0.31285, saving model to ./model/20-0.3129.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.3101 - accuracy: 0.8594 - val_loss: 0.3129 - val_accuracy: 0.8618\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.8683\n",
      "Epoch 21: val_loss did not improve from 0.31285\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.2967 - accuracy: 0.8683 - val_loss: 0.3595 - val_accuracy: 0.8684\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.8862\n",
      "Epoch 22: val_loss did not improve from 0.31285\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.2867 - accuracy: 0.8862 - val_loss: 0.3904 - val_accuracy: 0.8750\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.8817\n",
      "Epoch 23: val_loss did not improve from 0.31285\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.2777 - accuracy: 0.8817 - val_loss: 0.3451 - val_accuracy: 0.8816\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.8571\n",
      "Epoch 24: val_loss did not improve from 0.31285\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.3075 - accuracy: 0.8571 - val_loss: 0.3494 - val_accuracy: 0.8750\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.8616\n",
      "Epoch 25: val_loss improved from 0.31285 to 0.30998, saving model to ./model/25-0.3100.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.2995 - accuracy: 0.8616 - val_loss: 0.3100 - val_accuracy: 0.8750\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.8839\n",
      "Epoch 26: val_loss did not improve from 0.30998\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.2664 - accuracy: 0.8839 - val_loss: 0.3725 - val_accuracy: 0.8750\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9107\n",
      "Epoch 27: val_loss improved from 0.30998 to 0.26931, saving model to ./model/27-0.2693.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.2188 - accuracy: 0.9107 - val_loss: 0.2693 - val_accuracy: 0.8947\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.8929\n",
      "Epoch 28: val_loss improved from 0.26931 to 0.26074, saving model to ./model/28-0.2607.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.2711 - accuracy: 0.8929 - val_loss: 0.2607 - val_accuracy: 0.9013\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.8906\n",
      "Epoch 29: val_loss did not improve from 0.26074\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.2481 - accuracy: 0.8906 - val_loss: 0.3412 - val_accuracy: 0.8947\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9219\n",
      "Epoch 30: val_loss did not improve from 0.26074\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.2152 - accuracy: 0.9219 - val_loss: 0.2753 - val_accuracy: 0.8882\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.8996\n",
      "Epoch 31: val_loss did not improve from 0.26074\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.2744 - accuracy: 0.8996 - val_loss: 0.3478 - val_accuracy: 0.8882\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.8996\n",
      "Epoch 32: val_loss did not improve from 0.26074\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.2325 - accuracy: 0.8996 - val_loss: 0.2795 - val_accuracy: 0.8882\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9040\n",
      "Epoch 33: val_loss improved from 0.26074 to 0.22526, saving model to ./model/33-0.2253.hdf5\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.2300 - accuracy: 0.9040 - val_loss: 0.2253 - val_accuracy: 0.9079\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9487\n",
      "Epoch 34: val_loss improved from 0.22526 to 0.20102, saving model to ./model/34-0.2010.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.1584 - accuracy: 0.9487 - val_loss: 0.2010 - val_accuracy: 0.9276\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9219\n",
      "Epoch 35: val_loss improved from 0.20102 to 0.18272, saving model to ./model/35-0.1827.hdf5\n",
      "90/90 [==============================] - 9s 95ms/step - loss: 0.1942 - accuracy: 0.9219 - val_loss: 0.1827 - val_accuracy: 0.9211\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9152\n",
      "Epoch 36: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.2055 - accuracy: 0.9152 - val_loss: 0.2218 - val_accuracy: 0.8947\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9241\n",
      "Epoch 37: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.1744 - accuracy: 0.9241 - val_loss: 0.3839 - val_accuracy: 0.8553\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9174\n",
      "Epoch 38: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.2151 - accuracy: 0.9174 - val_loss: 0.3078 - val_accuracy: 0.8684\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9286\n",
      "Epoch 39: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1747 - accuracy: 0.9286 - val_loss: 0.3622 - val_accuracy: 0.8684\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9263\n",
      "Epoch 40: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.2060 - accuracy: 0.9263 - val_loss: 0.2190 - val_accuracy: 0.9145\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9330\n",
      "Epoch 41: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1783 - accuracy: 0.9330 - val_loss: 0.3724 - val_accuracy: 0.8684\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9375\n",
      "Epoch 42: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1807 - accuracy: 0.9375 - val_loss: 0.2406 - val_accuracy: 0.9211\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9375\n",
      "Epoch 43: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1456 - accuracy: 0.9375 - val_loss: 0.1930 - val_accuracy: 0.9145\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9442\n",
      "Epoch 44: val_loss did not improve from 0.18272\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1563 - accuracy: 0.9442 - val_loss: 0.2533 - val_accuracy: 0.8882\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9375\n",
      "Epoch 45: val_loss improved from 0.18272 to 0.13415, saving model to ./model/45-0.1341.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.1551 - accuracy: 0.9375 - val_loss: 0.1341 - val_accuracy: 0.9342\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9397\n",
      "Epoch 46: val_loss improved from 0.13415 to 0.11790, saving model to ./model/46-0.1179.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.1551 - accuracy: 0.9397 - val_loss: 0.1179 - val_accuracy: 0.9408\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9085\n",
      "Epoch 47: val_loss did not improve from 0.11790\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.1815 - accuracy: 0.9085 - val_loss: 0.1735 - val_accuracy: 0.9211\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9464\n",
      "Epoch 48: val_loss did not improve from 0.11790\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1400 - accuracy: 0.9464 - val_loss: 0.1328 - val_accuracy: 0.9276\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9375\n",
      "Epoch 49: val_loss did not improve from 0.11790\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.1843 - val_accuracy: 0.9079\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9509\n",
      "Epoch 50: val_loss did not improve from 0.11790\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1331 - accuracy: 0.9509 - val_loss: 0.1421 - val_accuracy: 0.9408\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9420\n",
      "Epoch 51: val_loss did not improve from 0.11790\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1351 - accuracy: 0.9420 - val_loss: 0.1410 - val_accuracy: 0.9474\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9509\n",
      "Epoch 52: val_loss improved from 0.11790 to 0.10510, saving model to ./model/52-0.1051.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.1236 - accuracy: 0.9509 - val_loss: 0.1051 - val_accuracy: 0.9539\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9353\n",
      "Epoch 53: val_loss did not improve from 0.10510\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1565 - accuracy: 0.9353 - val_loss: 0.1449 - val_accuracy: 0.9408\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9487\n",
      "Epoch 54: val_loss did not improve from 0.10510\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.1441 - accuracy: 0.9487 - val_loss: 0.1646 - val_accuracy: 0.9342\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9308\n",
      "Epoch 55: val_loss improved from 0.10510 to 0.09567, saving model to ./model/55-0.0957.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.1432 - accuracy: 0.9308 - val_loss: 0.0957 - val_accuracy: 0.9539\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9464\n",
      "Epoch 56: val_loss did not improve from 0.09567\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1254 - accuracy: 0.9464 - val_loss: 0.1714 - val_accuracy: 0.9145\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9487\n",
      "Epoch 57: val_loss did not improve from 0.09567\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.1392 - accuracy: 0.9487 - val_loss: 0.2033 - val_accuracy: 0.9276\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9643\n",
      "Epoch 58: val_loss did not improve from 0.09567\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1192 - accuracy: 0.9643 - val_loss: 0.1158 - val_accuracy: 0.9474\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9531\n",
      "Epoch 59: val_loss improved from 0.09567 to 0.05038, saving model to ./model/59-0.0504.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.1277 - accuracy: 0.9531 - val_loss: 0.0504 - val_accuracy: 0.9868\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9531\n",
      "Epoch 60: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.1343 - accuracy: 0.9531 - val_loss: 0.1536 - val_accuracy: 0.9276\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9397\n",
      "Epoch 61: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1593 - accuracy: 0.9397 - val_loss: 0.0728 - val_accuracy: 0.9868\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9710\n",
      "Epoch 62: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0815 - accuracy: 0.9710 - val_loss: 0.0938 - val_accuracy: 0.9605\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9442\n",
      "Epoch 63: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1168 - accuracy: 0.9442 - val_loss: 0.0571 - val_accuracy: 0.9934\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9732\n",
      "Epoch 64: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0714 - accuracy: 0.9732 - val_loss: 0.0629 - val_accuracy: 0.9737\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9732\n",
      "Epoch 65: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0751 - accuracy: 0.9732 - val_loss: 0.0556 - val_accuracy: 0.9803\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9576\n",
      "Epoch 66: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.1052 - accuracy: 0.9576 - val_loss: 0.0567 - val_accuracy: 0.9803\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9732\n",
      "Epoch 67: val_loss did not improve from 0.05038\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0728 - accuracy: 0.9732 - val_loss: 0.0832 - val_accuracy: 0.9671\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9665\n",
      "Epoch 68: val_loss improved from 0.05038 to 0.04332, saving model to ./model/68-0.0433.hdf5\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.0866 - accuracy: 0.9665 - val_loss: 0.0433 - val_accuracy: 0.9803\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9643\n",
      "Epoch 69: val_loss did not improve from 0.04332\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0871 - accuracy: 0.9643 - val_loss: 0.0487 - val_accuracy: 0.9737\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9688\n",
      "Epoch 70: val_loss improved from 0.04332 to 0.03981, saving model to ./model/70-0.0398.hdf5\n",
      "90/90 [==============================] - 9s 95ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 0.0398 - val_accuracy: 0.9934\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9754\n",
      "Epoch 71: val_loss did not improve from 0.03981\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0748 - accuracy: 0.9754 - val_loss: 0.0420 - val_accuracy: 0.9803\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9487\n",
      "Epoch 72: val_loss improved from 0.03981 to 0.03503, saving model to ./model/72-0.0350.hdf5\n",
      "90/90 [==============================] - 8s 92ms/step - loss: 0.1092 - accuracy: 0.9487 - val_loss: 0.0350 - val_accuracy: 0.9934\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9464\n",
      "Epoch 73: val_loss did not improve from 0.03503\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.1314 - accuracy: 0.9464 - val_loss: 0.0407 - val_accuracy: 0.9803\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9821\n",
      "Epoch 74: val_loss did not improve from 0.03503\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0355 - val_accuracy: 0.9934\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9754\n",
      "Epoch 75: val_loss improved from 0.03503 to 0.02760, saving model to ./model/75-0.0276.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.0707 - accuracy: 0.9754 - val_loss: 0.0276 - val_accuracy: 0.9934\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9777\n",
      "Epoch 76: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.0646 - accuracy: 0.9777 - val_loss: 0.0497 - val_accuracy: 0.9737\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9821\n",
      "Epoch 77: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0554 - accuracy: 0.9821 - val_loss: 0.0407 - val_accuracy: 0.9803\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9710\n",
      "Epoch 78: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0803 - accuracy: 0.9710 - val_loss: 0.0697 - val_accuracy: 0.9671\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9799\n",
      "Epoch 79: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 0.0683 - val_accuracy: 0.9737\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9643\n",
      "Epoch 80: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0825 - accuracy: 0.9643 - val_loss: 0.0959 - val_accuracy: 0.9671\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9777\n",
      "Epoch 81: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0550 - accuracy: 0.9777 - val_loss: 0.0669 - val_accuracy: 0.9737\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9799\n",
      "Epoch 82: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0573 - accuracy: 0.9799 - val_loss: 0.1057 - val_accuracy: 0.9408\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9598\n",
      "Epoch 83: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0921 - accuracy: 0.9598 - val_loss: 0.0762 - val_accuracy: 0.9671\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9710\n",
      "Epoch 84: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 91ms/step - loss: 0.0780 - accuracy: 0.9710 - val_loss: 0.0893 - val_accuracy: 0.9737\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9754\n",
      "Epoch 85: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 9s 94ms/step - loss: 0.0821 - accuracy: 0.9754 - val_loss: 0.0575 - val_accuracy: 0.9671\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9688\n",
      "Epoch 86: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.1053 - accuracy: 0.9688 - val_loss: 0.1250 - val_accuracy: 0.9605\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9754\n",
      "Epoch 87: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0627 - accuracy: 0.9754 - val_loss: 0.0812 - val_accuracy: 0.9671\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9754\n",
      "Epoch 88: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0726 - accuracy: 0.9754 - val_loss: 0.0680 - val_accuracy: 0.9671\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9688\n",
      "Epoch 89: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0703 - accuracy: 0.9688 - val_loss: 0.1557 - val_accuracy: 0.9474\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9710\n",
      "Epoch 90: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0718 - accuracy: 0.9710 - val_loss: 0.0884 - val_accuracy: 0.9605\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9821\n",
      "Epoch 91: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.0895 - val_accuracy: 0.9737\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9710\n",
      "Epoch 92: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0670 - accuracy: 0.9710 - val_loss: 0.1644 - val_accuracy: 0.9211\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9866\n",
      "Epoch 93: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.0887 - val_accuracy: 0.9539\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9777\n",
      "Epoch 94: val_loss did not improve from 0.02760\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0741 - accuracy: 0.9777 - val_loss: 0.0444 - val_accuracy: 0.9934\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9799\n",
      "Epoch 95: val_loss improved from 0.02760 to 0.02758, saving model to ./model/95-0.0276.hdf5\n",
      "90/90 [==============================] - 8s 92ms/step - loss: 0.0506 - accuracy: 0.9799 - val_loss: 0.0276 - val_accuracy: 0.9803\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9754\n",
      "Epoch 96: val_loss improved from 0.02758 to 0.02699, saving model to ./model/96-0.0270.hdf5\n",
      "90/90 [==============================] - 8s 92ms/step - loss: 0.0767 - accuracy: 0.9754 - val_loss: 0.0270 - val_accuracy: 0.9868\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9821\n",
      "Epoch 97: val_loss improved from 0.02699 to 0.01972, saving model to ./model/97-0.0197.hdf5\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.0197 - val_accuracy: 0.9934\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9710\n",
      "Epoch 98: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0829 - accuracy: 0.9710 - val_loss: 0.0231 - val_accuracy: 0.9868\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9799\n",
      "Epoch 99: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0393 - accuracy: 0.9799 - val_loss: 0.0296 - val_accuracy: 0.9934\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9933\n",
      "Epoch 100: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0341 - accuracy: 0.9933 - val_loss: 0.0411 - val_accuracy: 0.9737\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9866\n",
      "Epoch 101: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.0477 - val_accuracy: 0.9737\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9844\n",
      "Epoch 102: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0390 - accuracy: 0.9844 - val_loss: 0.0577 - val_accuracy: 0.9671\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9754\n",
      "Epoch 103: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0791 - accuracy: 0.9754 - val_loss: 0.0578 - val_accuracy: 0.9671\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9732\n",
      "Epoch 104: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0682 - accuracy: 0.9732 - val_loss: 0.0582 - val_accuracy: 0.9803\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9955\n",
      "Epoch 105: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0322 - accuracy: 0.9955 - val_loss: 0.0316 - val_accuracy: 0.9868\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9866\n",
      "Epoch 106: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.0494 - val_accuracy: 0.9934\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9911\n",
      "Epoch 107: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 85ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.0377 - val_accuracy: 0.9803\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9710\n",
      "Epoch 108: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.0702 - accuracy: 0.9710 - val_loss: 0.0439 - val_accuracy: 0.9803\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9777\n",
      "Epoch 109: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0425 - accuracy: 0.9777 - val_loss: 0.0511 - val_accuracy: 0.9803\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9799\n",
      "Epoch 110: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0430 - accuracy: 0.9799 - val_loss: 0.0485 - val_accuracy: 0.9803\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9821\n",
      "Epoch 111: val_loss did not improve from 0.01972\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.0605 - val_accuracy: 0.9605\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9821\n",
      "Epoch 112: val_loss improved from 0.01972 to 0.01214, saving model to ./model/112-0.0121.hdf5\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.0512 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9911\n",
      "Epoch 113: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0353 - accuracy: 0.9911 - val_loss: 0.0268 - val_accuracy: 0.9868\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9710\n",
      "Epoch 114: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 91ms/step - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.0624 - val_accuracy: 0.9671\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9821\n",
      "Epoch 115: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 90ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.0247 - val_accuracy: 0.9934\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9754\n",
      "Epoch 116: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0543 - accuracy: 0.9754 - val_loss: 0.0279 - val_accuracy: 0.9868\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 117: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9934\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9821\n",
      "Epoch 118: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0479 - accuracy: 0.9821 - val_loss: 0.0374 - val_accuracy: 0.9803\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9866\n",
      "Epoch 119: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0380 - accuracy: 0.9866 - val_loss: 0.0305 - val_accuracy: 0.9934\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9911\n",
      "Epoch 120: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0189 - val_accuracy: 0.9934\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9888\n",
      "Epoch 121: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0421 - accuracy: 0.9888 - val_loss: 0.0590 - val_accuracy: 0.9803\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9844\n",
      "Epoch 122: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0328 - accuracy: 0.9844 - val_loss: 0.0481 - val_accuracy: 0.9868\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9777\n",
      "Epoch 123: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0687 - accuracy: 0.9777 - val_loss: 0.0736 - val_accuracy: 0.9803\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9866\n",
      "Epoch 124: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 89ms/step - loss: 0.0489 - accuracy: 0.9866 - val_loss: 0.0484 - val_accuracy: 0.9868\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9911\n",
      "Epoch 125: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 88ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.1089 - val_accuracy: 0.9539\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9911\n",
      "Epoch 126: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0219 - accuracy: 0.9911 - val_loss: 0.1215 - val_accuracy: 0.9605\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9754\n",
      "Epoch 127: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0568 - accuracy: 0.9754 - val_loss: 0.0996 - val_accuracy: 0.9539\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9866\n",
      "Epoch 128: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 0.0722 - val_accuracy: 0.9737\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9911\n",
      "Epoch 129: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 86ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0533 - val_accuracy: 0.9671\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9888\n",
      "Epoch 130: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0290 - accuracy: 0.9888 - val_loss: 0.0519 - val_accuracy: 0.9868\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9799\n",
      "Epoch 131: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 94ms/step - loss: 0.0630 - accuracy: 0.9799 - val_loss: 0.0569 - val_accuracy: 0.9803\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9933\n",
      "Epoch 132: val_loss did not improve from 0.01214\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0554 - val_accuracy: 0.9868\n",
      "\n",
      "-----------------------------\n",
      "Training Accuracy: 0.9821\n",
      "Training Loss: 0.0512\n",
      "Validation Accuracy: 1.0\n",
      "Validation Loss: 0.0121\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "batch_size = 20\n",
    "num_classes = 2\n",
    "epochs = 200    #EarlyStopping Ï†ÅÏö©(ÏïàÎèåÏïÑÍ∞ÄÎ©¥ 30Ìöå)\n",
    "input_shape = (224, 224, 3)   #ÏΩîÎìú Î≥ÄÍ≤Ω\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists('./model/'):\n",
    "    os.mkdir('./model/')\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model1.fit(train_generator, \n",
    "                     epochs=epochs,\n",
    "                     validation_data=test_generator, #validation_steps=4,\n",
    "                     verbose=1, callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "patience = 20\n",
    "\n",
    "print(\"\\n-----------------------------\")\n",
    "print(f\"Training Accuracy: {round(history.history['accuracy'][-1 * patience -1], 4)}\")\n",
    "print(f\"Training Loss: {round(history.history['loss'][-1 * patience - 1], 4)}\")\n",
    "print(f\"Validation Accuracy: {round(history.history['val_accuracy'][-1 * patience - 1], 4)}\")\n",
    "print(f\"Validation Loss: {round(history.history['val_loss'][-1 * patience - 1], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx3px4MgE2sa"
   },
   "outputs": [],
   "source": [
    "# Î™®Îç∏ Ï†ÄÏû•ÌïòÍ∏∞\n",
    "MIX_MODEL_DIR = './model/mixed_data'\n",
    "if not os.path.exists(MIX_MODEL_DIR):\n",
    "    os.mkdir(MIX_MODEL_DIR)\n",
    "\n",
    "#__ Î∂ÄÎ∂Ñ: Î≥∏Ïù∏ Îç∞Ïù¥ÌÑ∞ ÌòïÏãù Ï†ÅÍ∏∞\n",
    "model1.save('mixed_data_mobilenetBasic_img_aug_cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
